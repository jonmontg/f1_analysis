---
title: "Formula 1 Data Analysis"
author: "Jon Montgomery"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

# Formula 1 Data Analysis

### 1.
In this project, we will explore the Formula 1 World Championship data from
1950 to 2024. The data set is available [on kaggle](https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020). 
It consists of various CSV files containing tabular data regarding drivers, 
circuits, teams, and results ranging from the granularity of championship
standings to pit stop characteristics. The data are very high quality.

I will be working with Abhishek on this project.

### 2.
We want to use the historical data to create a Markov Chain model to predict
the performance of a driver in the next race. We want to test the effectiveness
of the Markov Chain predictions against naive models to see if we can gain an
edge. Here are some examples of naive models:\newline
1. A driver's performance is random. \newline
2. A driver's performance in the next race will be the same as their performance
in the prior race. \newline
3. A driver's performance in the next race will be equal to the average of their
performance in the prior 10 races. \newline

We will split the data into random samplings of training and test data (60%
training and 40% test). Once the model is trained, we will evaluate the
performance of each model against the test data using the mean absolute error
metric, where the error is the difference between the predicted driver rank
and the actual driver rank.

Once we have calculated the mean absolute error for each model, we will test
the differences in the errors for statistical significance. The method we will
use to test for statistical significance will depend on whether or not the
errors are normally distributed. If the errors are normally distributed, we will
compare the results with the paired t-test. If the errors are not normally
distributed, we will use the Wilcoxon signed-rank test.

### 3.
We will use git for version control in this project. Abhishek and I will both
do preliminary data cleaning and exploration and then merge our findings. I will
build the markov models and most of the code infrastructure for the project.
Then Abhishek will review, we will test the models, and Abhishek will compile
slides for the presentation. Once we have the data, we will write the paper,
dividing it between us depending on who is most familiar with each part.

For cleaning and exploration, we will evaluate each table and field to decide
which variables could hold predictive power and should be included in the
Markov model. We will identify missing values and handle them appropriately
on a case-by-case basis. We will also identify the breakpoints between seasons
with discontinuous car specifications (every 8 years or so the "formula" of the
cars changes drastically). We'll divide the data randomly into testing and
training data and evaluate the models. We will complete this portion of the
project this weekend March 2.

I'll build the Markov Chains between March 3-7 and we will train them and do
analysis over the weekend March 8-9. We will spend the rest of our time preparing
the paper and the presentation.

```{r}
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(ggplot2)
library(knitr)
library(unifed)
library(readr)
library(dplyr)
library(slider)
library(markovchain)
library(xgboost)
library(Matrix)
library(caret)
library(zoo)
library(mltools)

set.seed(53782)
```

Markov Chain Parameters

 - circuit id
 - driver id
 - driver's average rank over the past 10 races
 - driver's most recent rank
 - qualifying position
 - constructor id
 - constructor rank
 - constructor's median pit stop time in the past 10 races
 - weather ?

One row per driver per race.

We will not make predictions for the first race of the season or for drivers with
fewer than 10 races. For each prediction, we only include the information that
we know right before the race starts.

### Read the data into dataframes
```{r}
circuits<-
  read_csv(file.path("data", "circuits.csv"),
           col_types  = cols(
           circuitId  = col_integer(),
           circuitRef = col_character(),
           name       = col_character(),
           location   = col_character(),
           country    = col_character(),
           lat        = col_double(),
           lng        = col_double(),
           alt        = col_integer(),
           url        = col_character())) %>%
  select(-c(
    "circuitRef",
    "location",
    "country",
    "lat",
    "lng",
    "alt",
    "url")) %>%
  rename(circuitName=name)

constructor.standings<-
  read_csv(file.path("data", "constructor_standings.csv"),
           col_types = cols(
             constructorStandingsId = col_integer(),
             raceId                 = col_integer(),
             constructorId          = col_integer(),
             points                 = col_double(),
             position               = col_integer(),
             positionText           = col_character(),
             wins                   = col_integer())) %>%
  select(-c(
    "points",
    "positionText",
    "wins")) %>%
  rename(constructorStandingsPosition = position)

constructors<-
  read_csv(file.path("data", "constructors.csv"),
           col_types = cols(
             constructorId  = col_integer(),
             constructorRef = col_character(),
             name           = col_character(),
             nationality    = col_character(),
             url            = col_character())) %>%
  select(-c(
    "nationality",
    "url",
    "constructorRef")) %>%
  rename(constructorName = name)

driver.standings<-
  read_csv(file.path("data", "driver_standings.csv"),
           col_types = cols(
             driverStandingsId = col_integer(),
             raceId            = col_integer(),
             driverId          = col_integer(),
             points            = col_double(),
             position          = col_integer(),
             positionText      = col_character(),
             wins              = col_integer())) %>%
  select(-c(
    "points",
    "positionText",
    "wins")) %>%
  rename(driverStandingsPosition = position)

drivers<-
  read_csv(file.path("data", "drivers.csv"),
           col_types = cols(
             driverId =    col_integer(),
             driverRef =   col_character(),
             number =      col_character(),
             code =        col_character(),
             forename =    col_character(),
             surname =     col_character(),
             dob =         col_date(),
             nationality = col_character(),
             url =         col_character())) %>%
  select(-c(
    "number",
    "code",
    "dob",
    "nationality",
    "url",
    "driverRef"))

races<-
  read_csv(file.path("data", "races.csv"),
           col_types = cols(
             raceId =    col_integer(),
             year =      col_integer(),
             round =     col_integer(),
             circuitId = col_integer(),
             name =      col_character(),
             date =      col_date(),
             time =      col_character(),
             url =       col_character(),
             fp1_date =  col_character(),
             fp1_time =  col_character())) %>%
  select(-c(
    "year",
    "name",
    "time",
    "url",
    "fp1_date",
    "fp1_time",
    "fp2_date",
    "fp2_time",
    "fp3_date",
    "fp3_time",
    "quali_date",
    "quali_time",
    "sprint_date",
    "sprint_time"))

results<-
  read_csv(file.path("data", "results.csv"),
           col_types = cols(
             resultId =      col_integer(),
             raceId =        col_integer(),
             driverId =      col_integer(),
             constructorId = col_integer(),
             number =        col_character(),
             grid =          col_integer(),
             position =      col_character(),
             positionText =  col_character(),
             positionOrder = col_integer(),
             points =        col_double())) %>%
  select(-c(
    "number",
    "position",
    "positionText",
    "points",
    "laps",
    "time",
    "milliseconds",
    "fastestLap",
    "rank",
    "fastestLapTime",
    "fastestLapSpeed")) %>%
  rename(raceResultPosition = positionOrder, startingPosition = grid)

status<-
  read_csv(file.path("data", "status.csv"),
           col_types = cols(
             statusId = col_integer(),
             status =   col_character()
           ))
```
### Creating the usable data

We only include results for drivers that have at least 10 races.

```{r}
get_mode <- function(x) {
  unique_x <- unique(x)
  unique_x[which.max(tabulate(match(x, unique_x)))]
}

get_qualitative_race_result <- function(x) {
  return(case_when(
      x == 1 ~         "win",
      x %in% c(2, 3) ~ "podium",
      x <= 10 ~        "score",
      TRUE ~           "no score"
    ))
}
encoded_qualitative_race_result <- function(x) {
  return(case_when(
    x == "win" ~      0,
    x == "podium" ~   1,
    x == "score" ~    2,
    x == "no score" ~ 3
  ))
}
decode_qualitative_race_result <- function(x) {
  return(case_when(
    x == 0 ~ "win",
    x == 1 ~ "podium",
    x == 2 ~ "score",
    x == 3 ~ "no score"
  ))
}

# Joining the datasets
data <- results %>%
  left_join(races, by = "raceId") %>%
  left_join(circuits, by = "circuitId") %>%
  left_join(drivers, by = "driverId") %>%
  left_join(constructors, by = "constructorId") %>%
  left_join(driver.standings, by = c("raceId", "driverId")) %>%
  left_join(constructor.standings, by = c("raceId", "constructorId")) %>%
  left_join(status, by = "statusId") %>%
  arrange(driverId, date) %>% # ensure the data is ordered correctly
  group_by(driverId) %>%
  mutate(
    meanRaceResult10 = slider::slide_dbl(raceResultPosition, mean, .before = 9, .complete = TRUE),
    status = case_when(
      status == "Finished" ~         "Finished",
      grepl("\\+\\d+ Lap", status) ~ "Lapped",
      TRUE ~                         "DNF"
    ),
    raceResultQualitative = get_qualitative_race_result(raceResultPosition)
  ) %>%
  mutate(
    modeQualitativeResult10 = rollapply(raceResultQualitative, width = 10, FUN = get_mode, 
                                         align = "right", fill = NA)
  ) %>%
  mutate(
    prevRaceResultPosition =           lag(raceResultPosition),
    prevDriverStandingsPosition =      lag(driverStandingsPosition),
    prevConstructorStandingsPosition = lag(constructorStandingsPosition),
    prevStatus =                       lag(status),
    prevMeanRaceResult10 =             lag(meanRaceResult10),
    prevModeQualitativeResult10 =      lag(modeQualitativeResult10),
    prevRaceResultQualitative =        lag(raceResultQualitative)
  ) %>%
  ungroup() %>%
  filter(!is.na(prevMeanRaceResult10) & !is.na(prevRaceResultPosition) & (round!=1))
data$driverStandingsPosition[is.na(data$driverStandingsPosition)] <- max(data$driverStandingsPosition, na.rm = TRUE)
data$constructorStandingsPosition[is.na(data$constructorStandingsPosition)] <- max(data$constructorStandingsPosition, na.rm = TRUE)
data$prevStatus[is.na(data$prevStatus)] <- "unknown"
```
### Accuracy Metric
```{r}
accuracy<-function(predictions, actual) {
  return(sum(actual == predictions) / length(actual))
}
```
### Building the Markov Chain
```{r}
get.trained.mc <- function(training.data.from, training.data.to) {
  # Ensure all unique states are included (as character)
  all_states <- as.character(unique(c(training.data.from, training.data.to)))

  # Create a transition table (ensuring all states are included)
  transition.table <- table(
    factor(training.data.from, levels = all_states), 
    factor(training.data.to, levels = all_states)
  )

  # Convert the table to a probability matrix
  transition.matrix <- prop.table(transition.table, margin = 1)

  # ✅ Explicitly convert "table" to a numeric matrix
  transition.matrix <- matrix(as.numeric(transition.matrix), 
                              nrow = length(all_states), 
                              dimnames = list(all_states, all_states))

  # Create and return the Markov Chain model
  return(new("markovchain", states = all_states, transitionMatrix = transition.matrix))
}
mc.predict<-function(mc, test.data) {
  return(sapply(test.data, function(x) rmarkovchain(n = 1, object = mc, t0 = x)))
}
```
### XGBoost
```{r}
library(data.table)
library(mltools)
encodeRaceResult<-function(x) {
  return case_when(
      x == "Finished" ~         "Finished",
      x ==  ~ "Lapped",
      TRUE ~                         "DNF"
    )
}

# Convert categorical variables using one-hot encoding
data.xgboost <- as.data.table(data)
data.xgboost[, `:=`(
  circuitId = as.factor(circuitId),
  constructorId = as.factor(constructorId),
  prevStatus = as.factor(prevStatus),
  raceResultQualitative = as.factor(raceResultQualitative)
)]

data.onehot <- one_hot(as.data.table(data.xgboost[, c(
  "circuitId",
  "constructorId",
  "prevStatus",
  "raceResultQualitative"
)]))

# Select numerical features
data.numeric <- data.xgboost[, c(
  "startingPosition",
  "prevDriverStandingsPosition",
  "prevConstructorStandingsPosition",
  "prevRaceResultPosition",
  "prevMeanRaceResult10"
)]

# Combine numerical and one-hot encoded categorical features
data.xgboost <- cbind(data.numeric, data.onehot)

# Convert target variable (raceResultQualitative) to numeric labels
print(data.xgboost)
data.xgboost$raceResultQualitative <- as.numeric(as.factor(data.xgboost$raceResultQualitative)) - 1

train.data.xgboost <- data.xgboost[train.index, ]
test.data.xgboost <- data.xgboost[-train.index, ]

# Separate features and labels
train.x <- as.matrix(train.data.xgboost)
train.y <- train.data.xgboost$raceResultQualitative

test.x <- as.matrix(test.data.xgboost)
test.y <- test.data.xgboost$raceResultQualitative


print(test.x)
# Convert to XGBoost DMatrix
dtrain <- xgb.DMatrix(data = train.x, label = train.y)
dtest <- xgb.DMatrix(data = test.x, label = test.y)

params <- list(
  objective = "multi:softmax", # Multi-class classification
  num_class = length(unique(data$raceResultQualitative)), # Number of classes
  eval_metric = "mlogloss", # Multi-class log loss
  eta = 0.1, # Learning rate
  max_depth = 6, # Tree depth
  subsample = 0.8, # Sample ratio
  colsample_bytree = 0.8 # Column sample ratio
)

# Train the XGBoost model
model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 100,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 1
)
preds <- predict(model, dtest)

# Convert numeric predictions back to original categories
preds <- as.factor(preds)
actual <- as.factor(test.y)

# Calculate accuracy
accuracy <- sum(preds == actual) / length(actual)
print(paste("Model Accuracy:", round(accuracy * 100, 2), "%"))

# Print confusion matrix
conf_matrix <- confusionMatrix(preds, actual)
print(conf_matrix)
```

### Naive Models
```{r}
naive.predict.same.as.last<-function(test.data) {
  return(test.data$prevRaceResultQualitative)
}
naive.predict.same.as.mode<-function(test.data) {
  return(test.data$prevModeQualitativeResult10)
}
naive.predict.same.as.start<-function(test.data) {
  return(sapply(test.data$startingPosition, function(x) get_qualitative_race_result(x)))
}
```

### Splitting the training and testing data
```{r}
train.index <- createDataPartition(1:nrow(data), p = 0.6, list = FALSE)
train.data <- data[train.index,]
test.data <- data[-train.index,]
```
### Training the Markov Chain
```{r}
mc <- get.trained.mc(train.data$prevRaceResultQualitative, train.data$raceResultQualitative)
```
### Test the Markov Chain
```{r}
predictions <- mc.predict(mc, test.data$prevRaceResultQualitative)
mc.accuracy <- accuracy(predictions, test.data$raceResultQualitative)
nsaa <- accuracy(naive.predict.same.as.mode(test.data),test.data$raceResultQualitative) 
nsal <- accuracy(naive.predict.same.as.last(test.data), test.data$raceResultQualitative)
nsas <- accuracy(naive.predict.same.as.start(test.data), test.data$raceResultQualitative)
print(mc.accuracy)
print(nsaa)
print(nsal)
print(nsas)
```